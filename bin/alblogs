#!/usr/bin/env ruby

require 'optparse'
require 'time'
require 'shellwords'
require 'json'
require 'alblogs'

def measure 
  start = Time.now
  yield
  Time.now - start
end
  
def display_stats(stats)
  stats[:elapsed_time] = Time.now.utc - stats[:started_at]
  $stderr.puts stats.inspect
end

started_at = Time.now.utc

options = {
  start_time: Alblogs::Utils.time_ago(started_at, '30 min'),
  end_time: started_at,
  include_filter: nil,
  exclude_filter: nil,
  alb_s3_bucket: nil,
  aws_profile: nil,
  log_file: $stdout,
  display_stats: false,
  request_times_over: nil
}
OptionParser.new do |opts|
  opts.banner = "Usage: alblogs [options]"

  opts.on("-s", "--start=TIME_EXP", "Start time") do |v|
    options[:start_time] = Alblogs::Utils.time_ago(started_at, v)
  end

  opts.on("-e", "--end=TIME_EXP", "End time") do |v|
    options[:end_time] = Alblogs::Utils.time_ago(started_at, v)
  end

  opts.on("--include=REGEX", "Include filter") do |v|
    options[:include_filter] = Regexp.new(v)
  end

  opts.on("--exclude=REGEX", "Exclude filter") do |v|
    options[:exclude_filter] = Regexp.new(v)
  end

  opts.on("-p", "--profile=PROFILE", "AWS profile") do |v|
    options[:aws_profile] = v
  end

  opts.on("-b", "--bucket=ALB_S3_BUCKET", "ALB S3 Bucket and Path") do |v|
    options[:alb_s3_bucket] = v
  end

  opts.on('-o', "--output=OUTPUT_FILE", 'File to stream matching ALB log entries to') do |v|
    f = File.open(v, 'wb')
    f.sync = true
    options[:log_file] = f
  end

  opts.on("--stats", "Display Stats") do
    options[:display_stats] = true
  end

  opts.on('--request-times-over=SECONDS', 'Find requests that took over X seconds') do |v|
    options[:request_times_over] = v.to_f
  end
end.parse!

raise("no bucket specified") unless options[:alb_s3_bucket]

# just forgive the user and swap the values
if options[:end_time] && options[:end_time] < options[:start_time]
  $stderr.puts 'swapping start/end times'
  options[:start_time], options[:end_time] = options[:end_time], options[:start_time]
end

request_matcher = Alblogs::RequestMatcher.new options

stats = Hash.new(0)
stats[:started_at] = started_at
stats[:range_starts_at] = request_matcher.range.begin
stats[:range_ends_at] = request_matcher.range.end
stats[:min_log_time] = nil
stats[:max_log_time] = nil
stats[:min_matched_log_time] = nil
stats[:max_matched_log_time] = nil

tmp_file = '.download.alblogs.log'
File.unlink(tmp_file) if File.exists?(tmp_file)
File.unlink("#{tmp_file}.gz") if File.exists?("#{tmp_file}.gz")

$stop = false
trap("INT") { $stop = true }

s3_bucket = Alblogs::S3Bucket.new(options[:alb_s3_bucket], options[:aws_profile])
s3_bucket.get_s3_files_in_range(request_matcher.range).values.each do |s3_file|
  stats[:files] += 1

  stats[:total_download_time] += measure do
    s3_bucket.download_s3_file(s3_file, tmp_file)
  end

  stats[:total_file_processing_time] += measure do
    File.open(tmp_file, 'rb') do |f|
      while(! f.eof? && ! $stop)
        stats[:lines] += 1
        line = f.readline
        entry = Alblogs::Entry.from_line(line)
        stats[:min_log_time] = ! stats[:min_log_time] || stats[:min_log_time] > entry.timestamp ? entry.timestamp : stats[:min_log_time]
        stats[:max_log_time] = ! stats[:max_log_time] || stats[:max_log_time] < entry.timestamp ? entry.timestamp : stats[:max_log_time]
        next unless request_matcher.match?(entry)
        stats[:matching_lines] += 1
        stats[:min_matched_log_time] = ! stats[:min_matched_log_time] || stats[:min_matched_log_time] > entry.timestamp ? entry.timestamp : stats[:min_matched_log_time]
        stats[:max_matched_log_time] = ! stats[:max_matched_log_time] || stats[:max_matched_log_time] < entry.timestamp ? entry.timestamp : stats[:max_matched_log_time]
        options[:log_file].puts line
      end
    end
  end

  File.unlink(tmp_file)

  display_stats(stats) if options[:display_stats]
  break if $stop
end

options[:log_file].close
